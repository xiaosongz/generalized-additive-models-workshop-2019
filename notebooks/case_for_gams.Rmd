---
title: "The Case for GAMs"
output: 
  html_notebook: 
    code_folding: none
    highlight: pygments
    theme: sandstone
editor_options: 
  chunk_output_type: inline
---

## Initialization

This assumes the prior Rmd files have been run.  See the README file.

```{r misc_functions, message=FALSE}
library(knitr)
# knitr::opts_knit(root.dir = getwd())
source('misc_functions/functions.R')
```

```{r load_packages}
library(tidyverse)
library(plotly)
library(modelr)
library(mgcv)
```


## Using Standard Methods

Let's see what happens when we apply standard methods to data that just doesn't work that way.  First we'll start with some generic data to illustrate the point.

```{r simulated_data}
set.seed(123)
library(mgcv)
dat = gamSim(1, n=400, dist="normal", scale=1, verbose=F)
```

We can use a basic linear regression and see how things go.

```{r demolm}
mod = lm(y ~ x1 + x2, data=dat)
summary(mod)
```

Everything is nice and tidy. We have straightforward information, positive effect of x1, negative for x2, and familiar output. Let’s look at some diagnostics.

```{r diagnostics}
plot(mod, which = 1:2)
```

Some issues might be present, as we might be getting a little more variance with some, especially higher, fitted values. We’re also a little loose in the tails of the distribution of the residuals. Let’s compare our predictions to the data. With a strong model, we might see a cigar shaped cloud converging to a line with slope 1 as the fit gets better. We seem to be having some issues here, as the residual plot noted above.

```{r general_fit}
# requires broom and glue packages
broom::augment(mod) %>% 
  ggplot(aes(x=.fitted, y=y)) +
  geom_point(alpha=.25, color='#ff5500') + 
  geom_smooth(se=F, color='#00aaff') +
  annotate('text',
           label = glue::glue("Rsq = {round(summary(mod)$r.squared, 2)}"),
           x = 4,
           y = 16) +
  labs(title='Fitted vs. Observed') +
  theme_minimal()
```

Now let’s go back and visualize the data. The following plots both predictors against the target variable.

```{r relationships}
dat %>% 
  select(x1, x2, y) %>% 
  gather(key=variable, value=Predictor, -y) %>% 
  ggplot(aes(x=Predictor, y=y)) +
  geom_point(alpha=.25, color='#ff5500') + 
  geom_smooth(aes(), color='#00aaff', se=F) +
  facet_grid(~variable) + 
  labs(title='Predictors vs. Y') +
  theme_trueMinimal()
```

So even with diagnostics that didn't appear too bad, we appear to not be capturing what's going on with the data that well at all!

## Heteroscedasticity, non-normality, etc.

We can try a log transformation. But this won't help us.

```{r log_no_help}
modlog = lm(log(y) ~ x1 + x2, dat)
summary(modlog)
plot(modlog, which = 1:2)

broom::augment(mod) %>% 
  ggplot(aes(x=.fitted, y=y)) +
  geom_point(alpha=.25, color='#ff5500') + 
  geom_smooth(se=F, color='#00aaff') +
  annotate('text',
           label = glue::glue("Rsq = {round(summary(modlog)$r.squared, 2)}"),
           x = 4,
           y = 16) +
  labs(title='Fitted vs. Observed') +
  theme_trueMinimal()
```


## Polynomial Regression

Likewise, we can try polynomial regression, but for most situations, the functional form is just something we might guess at, and/or it still won't help.  Let's look at a fairly complex relationship.

```{r simData}
set.seed(123)
x = runif(500)
mu = sin(2 * (4 * x - 2)) + 2 * exp(-(16 ^ 2) * ((x - .5) ^ 2))
y = rnorm(500, mu, .3)
d = data.frame(x,y) 
```


#### Polynomial regression is problematic

A standard linear regression is definitely not going to capture this relationship.  As above, we could try and use polynomial regression here, e.g. fitting a quadratic or cubic function within the standard regression framework.  However, this is unrealistic at best and at worst isn't useful for complex relationships. In the following, even with a polynomial of degree 15 the fit is fairly poor in many areas, and 'wiggles' in some places where there doesn't appear to be a need to.

```{r simDataPlot,message=F}
fits = sapply(seq(3,15, 3), function(p) fitted(lm(y~poly(x,p)))) %>% 
  data.frame(x, y, .) %>% 
  gather(key=polynomial, value=fits, -x, -y) %>% 
  mutate(polynomial = factor(polynomial, labels=seq(3,15, 3)))

plot_ly(data=d) %>% 
  add_markers(~x, ~y, marker=list(color='#ff5500', opacity=.2), showlegend=F) %>% 
  add_lines(~x, ~fits, color=~polynomial, data=fits) %>% 
  theme_plotly()
```



## GAM to the rescue!

```{r gam_vs_poly, warning=FALSE}
d %>% 
  qplot(data=., 
        x = x, 
        y = y, 
        geom=c('point', 'smooth'), 
        method = 'gam',
        formula = y ~ s(x))
```

